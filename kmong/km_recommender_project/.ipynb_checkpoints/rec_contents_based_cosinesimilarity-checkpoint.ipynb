{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78988634",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 및 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75310070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def preprocessing(x, stop_words):\n",
    "    okt = Okt()\n",
    "    try:\n",
    "        sentence_tokens = okt.nouns(x)\n",
    "        #result = ''\n",
    "        result = []\n",
    "        for token in sentence_tokens: \n",
    "            if token not in stop_words:\n",
    "                #result += ' ' + token \n",
    "                result.append(token)\n",
    "        return result\n",
    "    except:\n",
    "        return ['없음']\n",
    "        \n",
    "def rm_whitespace(x):\n",
    "    result = []\n",
    "    for i in x:\n",
    "        if i != '':\n",
    "            result.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "# evaluation metrices: Precision, Recall, NDCG@K\n",
    "def compute_metrics(pred_u, target_u, top_k):\n",
    "    pred_k = pred_u[:top_k]\n",
    "    num_target_items = len(target_u)\n",
    "\n",
    "    hits_k = [(i + 1, item) for i, item in enumerate(pred_k) if item in target_u]\n",
    "    # print(\"실제로 맞춘 items (position, idx):\", hits_k)\n",
    "    num_hits = len(hits_k)\n",
    "\n",
    "    idcg_k = 0.0\n",
    "    for i in range(1, min(num_target_items, top_k) + 1):\n",
    "        idcg_k += 1 / math.log(i + 1, 2)\n",
    "\n",
    "    dcg_k = 0.0\n",
    "    for idx, item in hits_k:\n",
    "        dcg_k += 1 / math.log(idx + 1, 2)\n",
    "    \n",
    "    prec_k = num_hits / top_k\n",
    "    recall_k = num_hits / min(num_target_items, top_k)\n",
    "    ndcg_k = dcg_k / idcg_k\n",
    "\n",
    "    return prec_k, recall_k, ndcg_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ba032",
   "metadata": {},
   "source": [
    "# 조건 설정하는 법\n",
    "    \n",
    "    1. 몇 편 이상의 유저로 사용할지\n",
    "        - 데이터 전처리 파트에 #### code ####와 같이 존재하는 부분으로 이동\n",
    "        - 아래 코드에 존재하는 숫자가 몇 편 이상으로 할지 선정\n",
    "            df_user_watch.loc[df_user_watch['cnt_watch']>=10].index\n",
    "    2. train-test 분리하는 법\n",
    "        - 데이터 전처리 파트에 마찬가지로 #### code ####와 같이 존재하는 부분으로 이동\n",
    "        - 랜덤 버전을 할 경우 #랜덤버전 아래의 코드 한줄만 앞의 코드에 #이 없도록 실행\n",
    "\n",
    "          train, test = train_test_split(df, test_size=0.2, stratify=df['userr'],random_state = 1234)\n",
    "          #flag_range = int(df.shape[0]*80)\n",
    "          #df= df.sort_values(by=['year','month','day','hour','min','sec'],ascending=True)\n",
    "          #train = df[:flag_range]\n",
    "          #test = df[flag_range:]\n",
    "\n",
    "        - 기간 선택 버전을 할 경우, #시간 선택 버전 아래의 코드들만 #을 없애고 실행\n",
    "          \n",
    "          #train, test = train_test_split(df, test_size=0.2, stratify=df['userr'],random_state = 1234)\n",
    "          flag_range = int(df.shape[0]*80)\n",
    "          df= df.sort_values(by=['year','month','day','hour','min','sec'],ascending=True)\n",
    "          train = df[:flag_range]\n",
    "          test = df[flag_range:]   \n",
    "     3. 이전에 시청한 영화를 평가에 포함할지\n",
    "         - 유저 평가하기 파트에 마찬가지로 #### code ####와 같이 존재하는 부분으로 이동\n",
    "         - 포함 시킬 경우, 아래와 같이 진행(진행할 코드에만 #을 제거)\n",
    "\n",
    "            #테스트할때 이전에 시청한 콘텐츠는 제외하고 평가하는것과 포함하여 평가하는것\n",
    "            # 특정 user가 본 영화들 제외\n",
    "            #train_items_by_user = train.loc[train.userr==user_id]\n",
    "            #unique_items = unique_items[~unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "            unique_items = unique_items\n",
    "            \n",
    "        - 미포함 시킬 경우, 아래와 같이 진행\n",
    "        \n",
    "            #테스트할때 이전에 시청한 콘텐츠는 제외하고 평가하는것과 포함하여 평가하는것\n",
    "            # 특정 user가 본 영화들 제외\n",
    "            train_items_by_user = train.loc[train.userr==user_id]\n",
    "            unique_items = unique_items[~unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "            #unique_items = unique_items\n",
    "    4. 변수 추가\n",
    "        - 해당 경우는 워낙 경우의 수가 많아서 완전하게 해드릴 수는 없을 것 같구요. 기본적으로 추가하는 방법을 알려드리지만,\n",
    "        오류가 나면 저한테 알려주시거나 한번 해결해보세요. \n",
    "        - 설명은 적어놓았는데 다음과 같습니다.\n",
    "\n",
    "           0. 아래의 과정들을 진행했는데도 오류가 난다면, 데이터 안에 값 자체를 전처리해주어야 합니다.\n",
    "                null,nan과 같은 결측값을 대체해주거나, 문자나 리스트와 같은 값들로 변경해주어야 합니다.\n",
    "                df['genre'] = df['genre'].apply(lambda x: x.split(\"|\"))\n",
    "                df['genre'] = df['genre'].apply(lambda x: rm_whitespace(x))\n",
    "                df['actors'] = df['actors'].fillna('없음')\n",
    "           1. 데이터 전처리 ~ 유저 평가하기 이전 까지의 코드 중에 수정할 곳들이 존재합니다\n",
    "           2. \"# n단계 조건 : 새로운 변수 추가\" 라는 주석이 존재하는 곳에 갑니다\n",
    "           3. \"# new_feature = 'genre_people_country'#<<여기에 해당 형식으로 추가\" 아래의 내용을 참고해서 코드를 완료합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2a9b4",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31993c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 커서 길이를 설정해놓았습니다. nrows=10000 자체를 없애거나 숫자를 변경해서 데이터 크기를 조정해보세요.\n",
    "df = pd.read_csv('test2.csv', nrows = 100000)\n",
    "df_stopwords = pd.read_csv('data/한국어불용어100.txt',sep='\\t', header=None,names=['words','b','c'])\n",
    "lst_words = df_stopwords['words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e58a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['userr','iitem1','ttime',\n",
    "             'title','subtitle','main_genre','genre',\n",
    "             'keyword','actors','country','price','summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56582870",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a301dba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19508/4187977937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrm_whitespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'없음'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19508/4187977937.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrm_whitespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'없음'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "df['summary'] = df['summary'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['summary'] = df['summary'].apply(lambda x: preprocessing(x, lst_words))\n",
    "\n",
    "# 1회 이상 시청 고객\n",
    "df_user_watch=pd.DataFrame(df['userr'].value_counts())\n",
    "df_user_watch.columns=['cnt_watch']\n",
    "#######################################################################################################\n",
    "# 학습데이터를 몇 편이상을 시청한 user로쓸지\n",
    "lst_user_real = df_user_watch.loc[df_user_watch['cnt_watch']>=10].index\n",
    "#######################################################################################################\n",
    "\n",
    "df = df.loc[df['userr'].isin(lst_user_real)]\n",
    "# 유저 아이디 인코딩\n",
    "le = LabelEncoder()\n",
    "df['userr'] = le.fit_transform(df['userr']).astype(int)\n",
    "\n",
    "df['genre'] = df['genre'].apply(lambda x: x.split(\"|\"))\n",
    "df['genre'] = df['genre'].apply(lambda x: rm_whitespace(x))\n",
    "df['actors'] = df['actors'].fillna('없음')\n",
    "df['country'] = df['country'].fillna('없음')\n",
    "df['genre'] = df['genre'].fillna('없음')\n",
    "df['year']=df['ttime'].apply(lambda x: str(x)[:4])\n",
    "df['month']=df['ttime'].apply(lambda x: str(x)[4:6])\n",
    "df['day']=df['ttime'].apply(lambda x: str(x)[6:8])\n",
    "df['hour']=df['ttime'].apply(lambda x: str(x)[8:10])\n",
    "df['min']=df['ttime'].apply(lambda x: str(x)[10:12])\n",
    "df['sec']=df['ttime'].apply(lambda x: str(x)[12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44103af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터셋의 user, item 수 확인\n",
    "user_list = list(df['userr'].unique())\n",
    "item_list = list(df['iitem1'].unique())\n",
    "num_users = len(user_list)\n",
    "num_items = len(item_list)\n",
    "\n",
    "# train, test set 나누기\n",
    "#######################################################################################################\n",
    "#train-test 나누기 \n",
    "#랜덤버전\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['userr'],random_state = 1234)\n",
    "#시간 선택 버전\n",
    "#flag_range = int(df.shape[0]*80)\n",
    "#df= df.sort_values(by=['year','month','day','hour','min','sec'],ascending=True)\n",
    "#train = df[:flag_range]\n",
    "#test = df[flag_range:]\n",
    "#######################################################################################################\n",
    "\n",
    "# 전체 데이터셋을 돌면서 모든 종류의 영화 장르, 국가, 배우 확인\n",
    "\n",
    "\n",
    "# 1단계 조건 : 새로운 변수 추가\n",
    "selected_features = [\"genre\", \"country\", \"actors\", \"summary\"] #<< 여기에 추가할 컬럼명 추가\n",
    "all_genre_list = []\n",
    "all_country_list = []\n",
    "all_people_list = []\n",
    "all_plot_list = [] \n",
    "# all_new_column_list = [] #<< 여기에 추가할 컬럼명으로 리스트 생성\n",
    "for index, row in train.iterrows():\n",
    "    genres = row[\"genre\"]\n",
    "    coutries = row[\"country\"]\n",
    "    people = row[\"actors\"]\n",
    "    plots = row[\"summary\"]\n",
    "    # new_columns = row['columns'] #<<여기에 해당 형식으로 추가\n",
    "    #for genre in genres:\n",
    "    #    if genre not in all_genre_list:\n",
    "    #        all_genre_list.append(genre) #<<여기에 해당 형식으로 추가\n",
    "    for genre in genres:\n",
    "        if genre not in all_genre_list:\n",
    "            all_genre_list.append(genre)\n",
    "    for country in coutries:\n",
    "        if country not in all_country_list:\n",
    "            all_country_list.append(country)\n",
    "    for person in people:\n",
    "        if person not in all_people_list:\n",
    "            all_people_list.append(person)\n",
    "    for plot in plots:\n",
    "        if plot not in all_plot_list:\n",
    "            all_plot_list.append(plot)\n",
    "num_genres = len(all_genre_list)\n",
    "num_countries = len(all_country_list)\n",
    "num_people = len(all_people_list)\n",
    "num_plot = len(all_plot_list)\n",
    "# num_column = len(all_new_columns_list) #<<여기에 해당 형식으로 추가\n",
    "\n",
    "# one-hot encoding\n",
    "def binary(feature_list, all_feature_list):\n",
    "    binary_list = []\n",
    "    for feature in all_feature_list:\n",
    "        if feature in feature_list:\n",
    "            binary_list.append(1)\n",
    "        else:\n",
    "            binary_list.append(0)\n",
    "    \n",
    "    return binary_list\n",
    "\n",
    "# 2단계 조건 : 새로운 변수 추가\n",
    "train['genre_bin'] = train['genre'].apply(lambda x: binary(x, all_genre_list))\n",
    "train['country_bin'] = train['country'].apply(lambda x: binary(x, all_country_list))\n",
    "train['people_bin'] = train['actors'].apply(lambda x: binary(x, all_people_list))\n",
    "train['plot_bin'] = train['summary'].apply(lambda x: binary(x, all_plot_list))\n",
    "#train['columns_bin'] = train['columns'].apply(lambda x: binary(x, all_columns_list)) #<<여기에 해당 형식으로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cac36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계 조건 : 새로운 변수 추가.\n",
    "new_feature = 'genre_plot'\n",
    "# new_feature = 'genre_people_country'#<<여기에 해당 형식으로 추가\n",
    "train[new_feature] = train['genre_bin'] + train['plot_bin']\n",
    "# train[new_feature] = train['genre_bin'] + train['people_bin'] + train['country_bin']#<<여기에 해당 형식으로 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5db374",
   "metadata": {},
   "source": [
    "## 특정 유저에 대해서 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6a0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum = train[new_feature].groupby(by=train['userr']).sum()\n",
    "num_features = len(train[new_feature].iloc[0])\n",
    "\n",
    "user_bin = {}\n",
    "for user_idx in user_list:\n",
    "    total_bin = np.zeros(num_features)\n",
    "    num_dim = int(len(grouped_sum[user_idx])/num_features)\n",
    "\n",
    "    for i in range(num_dim):\n",
    "        one_movie = np.array(grouped_sum[user_idx][i*num_features:(i+1)*num_features])\n",
    "        zipped_lists = zip(total_bin, one_movie)\n",
    "        total_bin = [x + y for (x, y) in zipped_lists]\n",
    "\n",
    "    total_bin = np.array(total_bin)\n",
    "    user_bin[user_idx] = (total_bin, num_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867d47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison@200: 0.0000\n",
      "Recall@200: 0.0000\n",
      "NDCG@200: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 특정 user의 one-hot vector 확인해보기\n",
    "user_id = 10\n",
    "total_bin = user_bin[user_id][0]\n",
    "num_movies = user_bin[user_id][1]\n",
    "\n",
    "# combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "norm_bin = total_bin / num_movies\n",
    "\n",
    "# unique item 추리기\n",
    "unique_items = train[['iitem1', 'title', 'genre', 'genre_bin', 'country', new_feature]].drop_duplicates(['iitem1'])\n",
    "\n",
    "#############################################################################\n",
    "#테스트할때 이전에 시청한 콘텐츠는 제외하고 평가하는것과 포함하여 평가하는것\n",
    "# 특정 user가 본 영화들 제외\n",
    "train_items_by_user = train.loc[train.userr==user_id]\n",
    "unique_items = unique_items[~unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "#unique_items = unique_items\n",
    "#############################################################################\n",
    "unique_items['similarity'] = unique_items[new_feature].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "unique_items.head()\n",
    "\n",
    "# cosine similarity를 토대로 top-k item 구하기\n",
    "sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "sorted_items.head()\n",
    "\n",
    "top_k = 10\n",
    "top_k_items = list(sorted_items['iitem1'][:top_k])\n",
    "top_item_df = sorted_items[['iitem1', 'title', 'genre']].drop_duplicates(['iitem1'])\n",
    "# 예측한 top-k items\n",
    "top_item_df[top_item_df['iitem1'].isin(top_k_items[:top_k])]\n",
    "\n",
    "# user가 실제로 본 영화들\n",
    "user_id = 10\n",
    "test_items_by_user = test.loc[test.userr==user_id]\n",
    "test_items_by_user[['userr', 'iitem1', 'title', 'genre']]\n",
    "\n",
    "# user 한 명에 대한 평가\n",
    "top_k = 200\n",
    "pred_u = list(sorted_items['iitem1'])\n",
    "target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "print(f\"Precison@{top_k}: {prec:.4f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.4f}\")\n",
    "print(f\"NDCG@{top_k}: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b0339",
   "metadata": {},
   "source": [
    "## 전체 유저에 대해서 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a8fcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@200: 0.0001\n",
      "Recall@200: 0.0082\n",
      "NDCG@200: 0.0029\n"
     ]
    }
   ],
   "source": [
    "# 전체 user에 대한 평가\n",
    "top_k = 200\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "# unique item 추리기\n",
    "ori_unique_items = train[['iitem1', 'title', 'genre', 'genre_bin', 'country', new_feature]].drop_duplicates(['iitem1'])\n",
    "\n",
    "for user_id in user_list:\n",
    "    total_bin = user_bin[user_id][0]\n",
    "    num_movies = user_bin[user_id][1]\n",
    "\n",
    "    # combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "    norm_bin = total_bin / num_movies\n",
    "\n",
    "    #############################################################################\n",
    "    #테스트할때 이전에 시청한 콘텐츠는 제외하고 평가하는것과 포함하여 평가하는것\n",
    "    # 특정 user가 본 영화들 제외\n",
    "    train_items_by_user = train.loc[train.userr==user_id]\n",
    "    unique_items = unique_items[~unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "    #unique_items = unique_items\n",
    "    #############################################################################\n",
    "    unique_items['similarity'] = unique_items[new_feature].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "\n",
    "    # cosine similarity를 토대로 top-k item 구하기\n",
    "    sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "\n",
    "    test_items_by_user = test.loc[test.userr==user_id]\n",
    "    pred_u = list(sorted_items['iitem1'])\n",
    "    target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "    prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "    prec_list.append(prec)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)\n",
    "\n",
    "print(f\"Precision@{top_k}: {np.mean(prec_list):.4f}\")\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15c41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc109ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ba3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564ce0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b211e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd86e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
