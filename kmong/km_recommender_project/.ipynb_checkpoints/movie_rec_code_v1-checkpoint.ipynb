{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f21dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11026824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3173: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/test.csv', nrows = 100000)\n",
    "df_stopwords = pd.read_csv('data/한국어불용어100.txt',sep='\\t', header=None,names=['words','b','c'])\n",
    "lst_words = df_stopwords['words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "38b11e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x, stop_words):\n",
    "    okt = Okt()\n",
    "    try:\n",
    "        sentence_tokens = okt.nouns(x)\n",
    "        #result = ''\n",
    "        result = []\n",
    "        for token in sentence_tokens: \n",
    "            if token not in stop_words:\n",
    "                #result += ' ' + token \n",
    "                result.append(token)\n",
    "        return result\n",
    "    except:\n",
    "        return ['없음']\n",
    "        \n",
    "def rm_whitespace(x):\n",
    "    result = []\n",
    "    for i in x:\n",
    "        if i != '':\n",
    "            result.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "    \n",
    "df['summary'] = df['summary'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['summary'] = df['summary'].apply(lambda x: preprocessing(x, lst_words))\n",
    "\n",
    "# 1회 이상 시청 고객\n",
    "df_user_watch=pd.DataFrame(df['userr'].value_counts())\n",
    "df_user_watch.columns=['cnt_watch']\n",
    "lst_user_real = df_user_watch.loc[df_user_watch['cnt_watch']>=10].index\n",
    "df = df.loc[df['userr'].isin(lst_user_real)]\n",
    "# 유저 아이디 인코딩\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['userr'] = le.fit_transform(df['userr']).astype(int)\n",
    "\n",
    "df['genre'] = df['genre'].apply(lambda x: x.split(\"|\"))\n",
    "df['genre'] = df['genre'].apply(lambda x: rm_whitespace(x))\n",
    "df['actors'] = df['actors'].fillna('없음')\n",
    "df['country'] = df['country'].fillna('없음')\n",
    "df['genre'] = df['genre'].fillna('없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f23b10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b45bc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users: 1132, # of items: 3929\n",
      "['키즈', 'TV만화', '노래율동', '외국어', '영어', '독서동화', '놀이교실', '애니', '시리즈', '액션/모험', '책', '방송', '드라마', 'MBC', '코믹/명랑', '예술교육', '영화', '극장판 애니', '액션', '노래 율동', '성인', '캐치온', 'KBS', '일본', 'SBS', '창의학습', '연예오락', 'TV조선', '미스터리/공포', 'tvN', '미드', '라이프', '예술', '클래식 콘서트', '중화TV', '오페라', '비디오물', 'SF/판타지', '해외시리즈', '중국', '판타지', 'JTBC', '어린이방송', '호러/공포', '수학과학', '코미디', '사극', '공포', '로맨스', '어린이/가족', '시사교양', '공연/무용', '무협', '해외', 'MCN', '스릴러', '한국', '온스타일', '추리/미스터리', 'EBS']\n",
      "# of genres:  60\n",
      "# of countries:  42\n",
      "# of people:  522\n",
      "# of plot:  7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋의 user, item 수 확인\n",
    "user_list = list(df['userr'].unique())\n",
    "item_list = list(df['iitem1'].unique())\n",
    "num_users = len(user_list)\n",
    "num_items = len(item_list)\n",
    "print(f\"# of users: {num_users}, # of items: {num_items}\")\n",
    "\n",
    "# train, test set 나누기\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['userr'],random_state = 1234)\n",
    "\n",
    "# 전체 데이터셋을 돌면서 모든 종류의 영화 장르, 국가, 배우 확인\n",
    "\n",
    "\n",
    "# genre, country, people\n",
    "selected_features = [\"genre\", \"country\", \"actors\", \"summary\"]\n",
    "all_genre_list = []\n",
    "all_country_list = []\n",
    "all_people_list = []\n",
    "all_plot_list = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    genres = row[\"genre\"]\n",
    "    coutries = row[\"country\"]\n",
    "    people = row[\"actors\"]\n",
    "    plots = row[\"summary\"]\n",
    "    #genres = ast.literal_eval(genres)\n",
    "    #coutries = ast.literal_eval(coutries)\n",
    "    #people = ast.literal_eval(people)\n",
    "    for genre in genres:\n",
    "        if genre not in all_genre_list:\n",
    "            all_genre_list.append(genre)\n",
    "    for country in coutries:\n",
    "        if country not in all_country_list:\n",
    "            all_country_list.append(country)\n",
    "    #print(people)\n",
    "    for person in people:\n",
    "        if person not in all_people_list:\n",
    "            all_people_list.append(person)\n",
    "    for plot in plots:\n",
    "        if plot not in all_plot_list:\n",
    "            all_plot_list.append(plot)\n",
    "num_genres = len(all_genre_list)\n",
    "num_countries = len(all_country_list)\n",
    "num_people = len(all_people_list)\n",
    "num_plot = len(all_plot_list)\n",
    "print(all_genre_list)\n",
    "print(\"# of genres: \", num_genres)\n",
    "print(\"# of countries: \", num_countries)\n",
    "print(\"# of people: \", num_people)\n",
    "print(\"# of plot: \", num_plot)\n",
    "\n",
    "# one-hot encoding\n",
    "def binary(feature_list, all_feature_list):\n",
    "    binary_list = []\n",
    "    for feature in all_feature_list:\n",
    "        if feature in feature_list:\n",
    "            binary_list.append(1)\n",
    "        else:\n",
    "            binary_list.append(0)\n",
    "    \n",
    "    return binary_list\n",
    "\n",
    "# genre, country, people feature\n",
    "train['genre_bin'] = train['genre'].apply(lambda x: binary(x, all_genre_list))\n",
    "train['country_bin'] = train['country'].apply(lambda x: binary(x, all_country_list))\n",
    "train['people_bin'] = train['actors'].apply(lambda x: binary(x, all_people_list))\n",
    "train['plot_bin'] = train['summary'].apply(lambda x: binary(x, all_plot_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07579ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15405b38",
   "metadata": {},
   "source": [
    "## 개별 변수 코사인 유사도 기반 추천 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "13ae68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users: 1132, # of items: 3929\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train[['user_id', 'item_id', 'title', 'genre_bin']].head()\n",
    "\n",
    "# 모든 user에 대해 combined one-hot vector 구하기\n",
    "# 영화 장르 (genre)에 대해서만 확인해보기\n",
    "grouped_sum = train['genre_bin'].groupby(by=train['userr']).sum()\n",
    "\n",
    "user_bin = {}\n",
    "for user_idx in user_list:\n",
    "    total_bin = np.zeros(num_genres)\n",
    "    num_movies = int(len(grouped_sum[user_idx])/num_genres)\n",
    "\n",
    "    for i in range(num_movies):\n",
    "        one_movie = np.array(grouped_sum[user_idx][i*num_genres:(i+1)*num_genres])\n",
    "        zipped_lists = zip(total_bin, one_movie)\n",
    "        total_bin = [x + y for (x, y) in zipped_lists]\n",
    "\n",
    "    total_bin = np.array(total_bin)\n",
    "    user_bin[user_idx] = (total_bin, num_movies)\n",
    "    \n",
    "# 특정 user의 one-hot vector 확인해보기\n",
    "user_id = 10\n",
    "total_bin = user_bin[user_id][0]\n",
    "num_movies = user_bin[user_id][1]\n",
    "print(f\"# of movies watched by user {user_id}: {num_movies}\")\n",
    "print(\"one-hot vector:\", total_bin)\n",
    "print(\"normalized one-hot vector:\", total_bin / num_movies)\n",
    "\n",
    "\n",
    "# combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "norm_bin = total_bin / num_movies\n",
    "\n",
    "# unique item 추리기\n",
    "unique_items = train[['iitem1', 'title', 'genre', 'genre_bin', 'country', ]].drop_duplicates(['iitem1'])\n",
    "\n",
    "# 특정 user가 본 영화들 제외\n",
    "train_items_by_user = train.loc[train.userr==user_id]\n",
    "unique_items = unique_items[~unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "\n",
    "unique_items['similarity'] = unique_items['genre_bin'].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "unique_items.head()\n",
    "\n",
    "# cosine similarity를 토대로 top-k item 구하기\n",
    "sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "sorted_items.head()\n",
    "\n",
    "top_k = 10\n",
    "top_k_items = list(sorted_items['iitem1'][:top_k])\n",
    "top_item_df = sorted_items[['iitem1', 'title', 'genre']].drop_duplicates(['iitem1'])\n",
    "# 예측한 top-k items\n",
    "top_item_df[top_item_df['iitem1'].isin(top_k_items[:top_k])]\n",
    "\n",
    "# user가 실제로 본 영화들\n",
    "user_id = 10\n",
    "test_items_by_user = test.loc[test.userr==user_id]\n",
    "test_items_by_user[['userr', 'iitem1', 'title', 'genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "abc5c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrices: Precision, Recall, NDCG@K\n",
    "def compute_metrics(pred_u, target_u, top_k):\n",
    "    pred_k = pred_u[:top_k]\n",
    "    num_target_items = len(target_u)\n",
    "\n",
    "    hits_k = [(i + 1, item) for i, item in enumerate(pred_k) if item in target_u]\n",
    "    # print(\"실제로 맞춘 items (position, idx):\", hits_k)\n",
    "    num_hits = len(hits_k)\n",
    "\n",
    "    idcg_k = 0.0\n",
    "    for i in range(1, min(num_target_items, top_k) + 1):\n",
    "        idcg_k += 1 / math.log(i + 1, 2)\n",
    "\n",
    "    dcg_k = 0.0\n",
    "    for idx, item in hits_k:\n",
    "        dcg_k += 1 / math.log(idx + 1, 2)\n",
    "    \n",
    "    prec_k = num_hits / top_k\n",
    "    recall_k = num_hits / min(num_target_items, top_k)\n",
    "    ndcg_k = dcg_k / idcg_k\n",
    "\n",
    "    return prec_k, recall_k, ndcg_k\n",
    "\n",
    "# user 한 명에 대한 평가\n",
    "top_k = 200\n",
    "pred_u = list(sorted_items['iitem1'])\n",
    "target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "print(f\"Precison@{top_k}: {prec:.4f}\")\n",
    "print(f\"Recall@{top_k}: {recall:.4f}\")\n",
    "print(f\"NDCG@{top_k}: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cf62bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 전체 user에 대한 평가\n",
    "top_k = 200\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "# unique item 추리기\n",
    "ori_unique_items = train[['iitem1', 'title', 'genre', 'genre_bin', 'country', ]].drop_duplicates(['iitem1'])\n",
    "\n",
    "for user_id in user_list:\n",
    "    total_bin = user_bin[user_id][0]\n",
    "    num_movies = user_bin[user_id][1]\n",
    "\n",
    "    # combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "    norm_bin = total_bin / num_movies\n",
    "\n",
    "    # 특정 user가 본 영화들 제외\n",
    "    train_items_by_user = train.loc[train.userr==user_id]\n",
    "    unique_items = ori_unique_items[~ori_unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "    unique_items['similarity'] = unique_items['genre_bin'].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "\n",
    "    # cosine similarity를 토대로 top-k item 구하기\n",
    "    sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "\n",
    "    test_items_by_user = test.loc[test.userr==user_id]\n",
    "    pred_u = list(sorted_items['iitem1'])\n",
    "    target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "    prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "    prec_list.append(prec)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)\n",
    "\n",
    "print(f\"Precision@{top_k}: {np.mean(prec_list):.4f}\")\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de29ed3",
   "metadata": {},
   "source": [
    "## 여러개의 feature로 코사인 유사도 기반 추천 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "39c79b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of genre: 60\n",
      "length of genre_plot: 7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 예시로 genre_bin와 people 두 개를 합치는 방식 사용.\n",
    "\n",
    "new_feature = 'genre_plot'\n",
    "# new_feature = 'genre_people'\n",
    "# new_feature = 'genre_people_country'\n",
    "train[new_feature] = train['genre_bin'] + train['plot_bin']\n",
    "# train[new_feature] = train['genre_bin'] + train['people_bin']\n",
    "# train[new_feature] = train['genre_bin'] + train['people_bin'] + train['country_bin']\n",
    "\n",
    "# one-hot vector 길이 변화 확인\n",
    "print(\"length of genre:\", len(train['genre_bin'].iloc[0]))\n",
    "print(f\"length of {new_feature}:\", len(train[new_feature].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69281a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sum = train[new_feature].groupby(by=train['userr']).sum()\n",
    "num_features = len(train[new_feature].iloc[0])\n",
    "\n",
    "user_bin = {}\n",
    "for user_idx in user_list:\n",
    "    total_bin = np.zeros(num_features)\n",
    "    num_dim = int(len(grouped_sum[user_idx])/num_features)\n",
    "\n",
    "    for i in range(num_dim):\n",
    "        one_movie = np.array(grouped_sum[user_idx][i*num_features:(i+1)*num_features])\n",
    "        zipped_lists = zip(total_bin, one_movie)\n",
    "        total_bin = [x + y for (x, y) in zipped_lists]\n",
    "\n",
    "    total_bin = np.array(total_bin)\n",
    "    user_bin[user_idx] = (total_bin, num_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f91e3cf8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3752/3514619741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrain_items_by_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muserr\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0munique_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mori_unique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mori_unique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iitem1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_items_by_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iitem1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0munique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'similarity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_bin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# cosine similarity를 토대로 top-k item 구하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3848\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3752/3514619741.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrain_items_by_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muserr\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0munique_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mori_unique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mori_unique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iitem1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_items_by_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iitem1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0munique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'similarity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_bin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# cosine similarity를 토대로 top-k item 구하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 전체 user에 대한 평가\n",
    "top_k = 200\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "# unique item 추리기\n",
    "ori_unique_items = train[['iitem1', 'title', 'genre', 'genre_bin', 'country', new_feature]].drop_duplicates(['iitem1'])\n",
    "\n",
    "for user_id in user_list:\n",
    "    total_bin = user_bin[user_id][0]\n",
    "    num_movies = user_bin[user_id][1]\n",
    "\n",
    "    # combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "    norm_bin = total_bin / num_movies\n",
    "\n",
    "    # 특정 user가 본 영화들 제외\n",
    "    train_items_by_user = train.loc[train.userr==user_id]\n",
    "    unique_items = ori_unique_items[~ori_unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "    unique_items['similarity'] = unique_items[new_feature].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "\n",
    "    # cosine similarity를 토대로 top-k item 구하기\n",
    "    sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "\n",
    "    test_items_by_user = test.loc[test.userr==user_id]\n",
    "    pred_u = list(sorted_items['iitem1'])\n",
    "    target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "    prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "    prec_list.append(prec)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)\n",
    "\n",
    "print(f\"Precision@{top_k}: {np.mean(prec_list):.4f}\")\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1d222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5176f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "175b5437",
   "metadata": {},
   "source": [
    "## w2v 추천 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d4098597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "from gensim.models import Word2Vec, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "4d11a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x, stop_words):\n",
    "    okt = Okt()\n",
    "    try:\n",
    "        sentence_tokens = okt.nouns(x['summary'])\n",
    "        genres = x['genre']\n",
    "        #result = ''\n",
    "        result = []\n",
    "        for token in sentence_tokens: \n",
    "            if token not in stop_words:\n",
    "                #result += ' ' + token \n",
    "                result.append(token)\n",
    "        for genre in genres:\n",
    "            result.append(genre)\n",
    "            \n",
    "        result.append(x['country'])\n",
    "        return result\n",
    "    except:\n",
    "        return ['없음']\n",
    "        \n",
    "def rm_whitespace(x):\n",
    "    result = []\n",
    "    for i in x:\n",
    "        if i != '':\n",
    "            result.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "    \n",
    "# 1회 이상 시청 고객\n",
    "df_user_watch=pd.DataFrame(df['userr'].value_counts())\n",
    "df_user_watch.columns=['cnt_watch']\n",
    "lst_user_real = df_user_watch.loc[df_user_watch['cnt_watch']>=10].index\n",
    "df = df.loc[df['userr'].isin(lst_user_real)]\n",
    "\n",
    "# 변수 전처리\n",
    "df['genre'] = df['genre'].apply(lambda x: x.split(\"|\"))\n",
    "df['genre'] = df['genre'].apply(lambda x: rm_whitespace(x))\n",
    "df['actors'] = df['actors'].fillna('없음')\n",
    "df['country'] = df['country'].fillna('없음')\n",
    "df['genre'] = df['genre'].fillna('없음')\n",
    "df['summary'] = df['summary'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['comebine_col'] = df.apply(lambda x: preprocessing(x, lst_words), axis=1)\n",
    "\n",
    "# 유저 아이디 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['userr'] = le.fit_transform(df['userr']).astype(str)\n",
    "le = LabelEncoder()\n",
    "df['iitem1'] = le.fit_transform(df['iitem1']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "feac6cbf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users: 1132, # of items: 3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3752/2719763722.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# 위에서 만든 tagged_train_docs으로 사전을 만들어줍니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged_train_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# 벡터 문서 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m         total_words, corpus_count = self.scan_vocab(\n\u001b[0;32m    879\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m             \u001b[0mprogress_per\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m         )\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         logger.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[1;34m(self, corpus_iterable, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m                 \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m             \u001b[0mtotal_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# movie title와 id를 매핑할 dictionary를 생성\n",
    "idx2title = {}\n",
    "for i, c in zip(df['iitem1'], df['title']): \n",
    "    idx2title[i] = c\n",
    "\n",
    "# id와 movie title를 매핑할 dictionary를 생성\n",
    "title2idx = {}\n",
    "for i, c in zip(df['iitem1'], df['title']): \n",
    "    title2idx[c] = i\n",
    "    \n",
    "    \n",
    "# 전체 데이터셋의 user, item 수 확인\n",
    "user_list = list(df['userr'].unique())\n",
    "item_list = list(df['iitem1'].unique())\n",
    "num_users = len(user_list)\n",
    "num_items = len(item_list)\n",
    "print(f\"# of users: {num_users}, # of items: {num_items}\")\n",
    "\n",
    "# train, test set 나누기\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify = df['userr'], random_state = 1234)\n",
    "\n",
    "# train set에 있는 user set\n",
    "train_users = train_df['userr'].unique()\n",
    "# sorting\n",
    "train_users = sorted(train_users)\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "train = []\n",
    "for user_id in train_users:\n",
    "    itemset = train_df[train_df['userr'] == user_id]['iitem1'].tolist()\n",
    "    train.append(itemset)\n",
    "    # print(itemset)\n",
    "    \n",
    "# test set에서도 동일하게 구성\n",
    "test_users = test_df['userr'].unique()\n",
    "# sorting\n",
    "test_users = sorted(test_users)\n",
    "\n",
    "test = []\n",
    "for user_id in test_users:\n",
    "    itemset = test_df[test_df['userr'] == user_id]['iitem1'].tolist()\n",
    "    test.append(itemset)\n",
    "\n",
    "model = doc2vec.Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=10,        # distance between the predicted word and context words\n",
    "    #size=100,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=5,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=4,   # multi cpu\n",
    "    hs = 1,          # hierar chical softmax / default 0\n",
    "    negative = 10   # negative sampling / default 5\n",
    ")\n",
    "\n",
    "# userId로 groupby해서 original_title의 unique 항목을 추출해줍니다. \n",
    "# 해당 코드를 통해서 사용자가 본 영화의 제목이 모두 저장됩니다. \n",
    "\n",
    "# Doc2Vec 입력형태를 맞춰줍니다. \n",
    "# TaggedDocument 형태로 ('영화 내용', '제목') 을 받습니다. \n",
    "## 이후, TaggedDocument에 모든 문서에 대해서 '영화 내용', '제목'을 넣어줍니다.\n",
    "\n",
    "agg = train_df[['iitem1', 'comebine_col']]\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument((c), [d]) for d, c in agg[['iitem1', 'comebine_col']].values]\n",
    "\n",
    "# 위에서 만든 tagged_train_docs으로 사전을 만들어줍니다. \n",
    "model.build_vocab(tagged_train_docs)\n",
    "\n",
    "# 벡터 문서 학습\n",
    "\n",
    "start = time()\n",
    "\n",
    "for epoch in range(5):\n",
    "    # Doc2Vec 학습을 진행하는데 Learning rate를 계속 감소해주면서 학습을 진행해줍니다. \n",
    "    model.train(tagged_train_docs, total_examples=model.corpus_count, epochs=10)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "7e5691f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  import sys\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "해당 유저는 평가가 되기 어렵습니다.\n",
      "Precision@200: 0.0000\n",
      "Recall@200: 0.0000\n",
      "NDCG@200: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 본 영화들의 embedding의 평균 계산\n",
    "def aggregate_vectors(movie_list):\n",
    "\n",
    "    product_vec = []\n",
    "    for i in movie_list:\n",
    "        try:\n",
    "            product_vec.append(model.docvecs[i])\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    return np.mean(product_vec, axis=0)\n",
    "\n",
    "# 전체 user에 대한 평가\n",
    "top_k = 200\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "for user_idx in train_df.userr.unique():\n",
    "    try:\n",
    "        movie_list = train_df[train_df['userr']==user_idx].iitem1.values\n",
    "        target_u = test_df[test_df['userr']==user_idx].iitem1.values\n",
    "        avg_emb = aggregate_vectors(movie_list)\n",
    "        #print(avg_emb)\n",
    "        sim_movies_all = model.docvecs.most_similar(avg_emb, topn=500)\n",
    "        # train에 없는 영화만 남기기\n",
    "        sim_movies = []\n",
    "        for i, _ in enumerate(sim_movies_all):\n",
    "            if sim_movies_all[i][0] not in movie_list:\n",
    "                sim_movies.append((sim_movies_all[i][0], sim_movies_all[i][1]))\n",
    "        # top-N movie list 반환\n",
    "        pred_u = []\n",
    "        for i, (idx, _) in enumerate(sim_movies):\n",
    "            pred_u.append(sim_movies[i][0])\n",
    "\n",
    "        prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "        prec_list.append(prec)\n",
    "        recall_list.append(recall)\n",
    "        ndcg_list.append(ndcg)\n",
    "    except:\n",
    "        print(\"해당 유저는 평가가 되기 어렵습니다.\")\n",
    "        prec_list.append(0)\n",
    "        recall_list.append(0)\n",
    "        ndcg_list.append(0)\n",
    "print(f\"Precision@{top_k}: {np.mean(prec_list):.4f}\")\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe169f",
   "metadata": {},
   "source": [
    "## tfidf 기반 추천시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1534678",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'LabelEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17320/3430109466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst_user_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# 유저 아이디 인코딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'LabelEncoder'"
     ]
    }
   ],
   "source": [
    "def preprocessing(x, stop_words):\n",
    "    okt = Okt()\n",
    "    try:\n",
    "        sentence_tokens = okt.nouns(x)\n",
    "        result = ''\n",
    "        #result = []\n",
    "        for token in sentence_tokens: \n",
    "            if token not in stop_words:\n",
    "                result += ' ' + token \n",
    "                #result.append(token)\n",
    "        return result\n",
    "    except:\n",
    "        return '없음'\n",
    "        \n",
    "def rm_whitespace(x):\n",
    "    result = []\n",
    "    for i in x:\n",
    "        if i != '':\n",
    "            result.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "def preprocessing_(x):\n",
    "    \n",
    "    genres = x['genre']\n",
    "    result = ''\n",
    "\n",
    "    for genre in genres:\n",
    "        result += ' ' + genre \n",
    "\n",
    "    result += ' ' + x['country']\n",
    "    result += ' ' + x['summary']\n",
    "    return result\n",
    "\n",
    "df['summary'] = df['summary'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['summary'] = df['summary'].apply(lambda x: preprocessing(x, lst_words))\n",
    "\n",
    "# 1회 이상 시청 고객\n",
    "df_user_watch=pd.DataFrame(df['userr'].value_counts())\n",
    "df_user_watch.columns=['cnt_watch']\n",
    "lst_user_real = df_user_watch.loc[df_user_watch['cnt_watch']>=10].index\n",
    "df = df.loc[df['userr'].isin(lst_user_real)]\n",
    "\n",
    "# 유저 아이디 인코딩\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['userr'] = le.fit_transform(df['userr']).astype(int)\n",
    "\n",
    "df['genre'] = df['genre'].apply(lambda x: x.split(\"|\"))\n",
    "df['genre'] = df['genre'].apply(lambda x: rm_whitespace(x))\n",
    "df['actors'] = df['actors'].fillna('없음')\n",
    "df['country'] = df['country'].fillna('없음')\n",
    "df['genre'] = df['genre'].fillna('없음')\n",
    "\n",
    "df['comebine_col'] = df.apply(lambda x: preprocessing_(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797f8fc0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users: 1132, # of items: 3929\n",
      "['키즈', 'TV만화', '노래율동', '외국어', '영어', '책', '놀이교실', '애니', '시리즈', '액션/모험', '방송', '드라마', 'MBC', '코믹/명랑', '예술교육', '영화', '극장판 애니', '액션', '노래 율동', '성인', '캐치온', '창의학습', 'SBS', '일본', '독서동화', '연예오락', 'TV조선', '미스터리/공포', '미드', '라이프', '예술', '클래식 콘서트', 'tvN', 'KBS', '중화TV', '오페라', '해외시리즈', '중국', '무협', '비디오물', 'SF/판타지', 'JTBC', '로맨스', '어린이방송', '사극', '수학과학', '코미디', '공포', '어린이/가족', '시사교양', '공연/무용', '호러/공포', '한국', '해외', '스릴러', 'MCN', '판타지', '추리/미스터리', '온스타일', 'EBS']\n",
      "# of genres:  60\n",
      "# of countries:  42\n",
      "# of people:  522\n",
      "# of plot:  1105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.17987848, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.14921647],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.29699165],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.28735289, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.23837083],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.63112701,\n",
       "         0.        ],\n",
       "        [0.29025564, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.24077878]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터셋의 user, item 수 확인\n",
    "user_list = list(df['userr'].unique())\n",
    "item_list = list(df['iitem1'].unique())\n",
    "num_users = len(user_list)\n",
    "num_items = len(item_list)\n",
    "print(f\"# of users: {num_users}, # of items: {num_items}\")\n",
    "\n",
    "# train, test set 나누기\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['userr'],random_state = 1234)\n",
    "\n",
    "# 전체 데이터셋을 돌면서 모든 종류의 영화 장르, 국가, 배우 확인\n",
    "\n",
    "\n",
    "# genre, country, people\n",
    "selected_features = [\"genre\", \"country\", \"actors\", \"summary\"]\n",
    "all_genre_list = []\n",
    "all_country_list = []\n",
    "all_people_list = []\n",
    "all_plot_list = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    genres = row[\"genre\"]\n",
    "    coutries = row[\"country\"]\n",
    "    people = row[\"actors\"]\n",
    "    plots = row[\"summary\"]\n",
    "    #genres = ast.literal_eval(genres)\n",
    "    #coutries = ast.literal_eval(coutries)\n",
    "    #people = ast.literal_eval(people)\n",
    "    for genre in genres:\n",
    "        if genre not in all_genre_list:\n",
    "            all_genre_list.append(genre)\n",
    "    for country in coutries:\n",
    "        if country not in all_country_list:\n",
    "            all_country_list.append(country)\n",
    "    #print(people)\n",
    "    for person in people:\n",
    "        if person not in all_people_list:\n",
    "            all_people_list.append(person)\n",
    "    for plot in plots:\n",
    "        if plot not in all_plot_list:\n",
    "            all_plot_list.append(plot)\n",
    "num_genres = len(all_genre_list)\n",
    "num_countries = len(all_country_list)\n",
    "num_people = len(all_people_list)\n",
    "num_plot = len(all_plot_list)\n",
    "print(all_genre_list)\n",
    "print(\"# of genres: \", num_genres)\n",
    "print(\"# of countries: \", num_countries)\n",
    "print(\"# of people: \", num_people)\n",
    "print(\"# of plot: \", num_plot)\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 10, sublinear_tf = True, max_features=50)\n",
    "tfidf_matrix = tfidf.fit_transform(train['comebine_col'].astype(str))\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "title_to_index = dict(zip(train['title'], train.index))\n",
    "\n",
    "tfidf_vector = []\n",
    "for val in np.array(tfidf_matrix.todense()):\n",
    "    tfidf_vector.append(val)\n",
    "train['tfidf_vector'] = tfidf_vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7cf7e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_sum = train['tfidf_vector'].groupby(by=train['userr']).sum()\n",
    "\n",
    "grouped_sum = train.groupby('userr')['tfidf_vector'].apply(lambda x: [sum(y) for y in zip(*x)])\n",
    "num_features = len(train['tfidf_vector'].iloc[0])\n",
    "\n",
    "user_bin = {}\n",
    "for user_idx in user_list:\n",
    "    total_bin = np.zeros(num_features)\n",
    "    num_dim = int(len(grouped_sum[user_idx])/num_features)\n",
    "\n",
    "    for i in range(num_dim):\n",
    "        one_movie = np.array(grouped_sum[user_idx][i*num_features:(i+1)*num_features])\n",
    "        zipped_lists = zip(total_bin, one_movie)\n",
    "        total_bin = [x + y for (x, y) in zipped_lists]\n",
    "\n",
    "    total_bin = np.array(total_bin)\n",
    "    user_bin[user_idx] = (total_bin, num_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b91260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrices: Precision, Recall, NDCG@K\n",
    "def compute_metrics(pred_u, target_u, top_k):\n",
    "    pred_k = pred_u[:top_k]\n",
    "    num_target_items = len(target_u)\n",
    "\n",
    "    hits_k = [(i + 1, item) for i, item in enumerate(pred_k) if item in target_u]\n",
    "    # print(\"실제로 맞춘 items (position, idx):\", hits_k)\n",
    "    num_hits = len(hits_k)\n",
    "\n",
    "    idcg_k = 0.0\n",
    "    for i in range(1, min(num_target_items, top_k) + 1):\n",
    "        idcg_k += 1 / math.log(i + 1, 2)\n",
    "\n",
    "    dcg_k = 0.0\n",
    "    for idx, item in hits_k:\n",
    "        dcg_k += 1 / math.log(idx + 1, 2)\n",
    "    \n",
    "    prec_k = num_hits / top_k\n",
    "    recall_k = num_hits / min(num_target_items, top_k)\n",
    "    ndcg_k = dcg_k / idcg_k\n",
    "\n",
    "    return prec_k, recall_k, ndcg_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a2a7ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@200: 0.0053\n",
      "Recall@200: 0.2917\n",
      "NDCG@200: 0.0874\n"
     ]
    }
   ],
   "source": [
    "# 전체 user에 대한 평가\n",
    "top_k = 200\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "ndcg_list = []\n",
    "\n",
    "# unique item 추리기\n",
    "ori_unique_items = train[['iitem1', 'title', 'genre', 'country', 'tfidf_vector']].drop_duplicates(['iitem1'])\n",
    "\n",
    "for user_id in user_list:\n",
    "    total_bin = user_bin[user_id][0]\n",
    "    num_movies = user_bin[user_id][1]\n",
    "\n",
    "    # combined one-hot vector를 가지고 다른 item들과의 cosine similarity 계산\n",
    "    norm_bin = total_bin / num_movies\n",
    "\n",
    "    # 특정 user가 본 영화들 제외\n",
    "    train_items_by_user = train.loc[train.userr==user_id]\n",
    "    unique_items = ori_unique_items[~ori_unique_items['iitem1'].isin(train_items_by_user['iitem1'])]\n",
    "    unique_items['similarity'] = unique_items['tfidf_vector'].apply(lambda x: np.array(x).dot(norm_bin) / (np.array(x).sum() + 1e-10))\n",
    "\n",
    "    # cosine similarity를 토대로 top-k item 구하기\n",
    "    sorted_items = unique_items.sort_values(by=['similarity'], axis=0, ascending=False)\n",
    "\n",
    "    test_items_by_user = test.loc[test.userr==user_id]\n",
    "    pred_u = list(sorted_items['iitem1'])\n",
    "    target_u = list(test_items_by_user['iitem1'])\n",
    "\n",
    "    prec, recall, ndcg = compute_metrics(pred_u, target_u, top_k)\n",
    "    prec_list.append(prec)\n",
    "    recall_list.append(recall)\n",
    "    ndcg_list.append(ndcg)\n",
    "\n",
    "print(f\"Precision@{top_k}: {np.mean(prec_list):.4f}\")\n",
    "print(f\"Recall@{top_k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"NDCG@{top_k}: {np.mean(ndcg_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2b19fe9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254fa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d96cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be973f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dca33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf310fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ac89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504adee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9d826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7e6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # 선택한 영화의 타이틀로부터 해당 영화의 인덱스를 받아온다.\n",
    "    idx = title_to_index[title]\n",
    "\n",
    "    # 해당 영화와 모든 영화와의 유사도를 가져온다.\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # 유사도에 따라 영화들을 정렬한다.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사한 10개의 영화를 받아온다.\n",
    "    sim_scores = list(set(sim_scores))[1:11]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 인덱스를 얻는다.\n",
    "    movie_indices = [idx[0] for idx in sim_scores]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 제목을 리턴한다.\n",
    "    return df['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b0df2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7826          우도주막\n",
       "6121       널 위해서라면\n",
       "9926       백종원 클라쓰\n",
       "3275       티라노사우르스\n",
       "6574        왕꽃 선녀님\n",
       "1314     해결사(2010)\n",
       "6777    천계지백사전설(하)\n",
       "4632          경찰수업\n",
       "9645     그대 없인 못살아\n",
       "2994       진시명월(상)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('사랑의 불시착')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b281a",
   "metadata": {},
   "source": [
    "# w2v 추천시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf7f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# userId로 groupby해서 original_title의 unique 항목을 추출해줍니다. \n",
    "# 해당 코드를 통해서 사용자가 본 영화의 제목이 모두 저장됩니다. \n",
    "agg = df.groupby(['userr'])['title'].agg({'unique'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a91766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = doc2vec.Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=10,        # distance between the predicted word and context words\n",
    "    #size=100,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=5,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=4,   # multi cpu\n",
    "    hs = 1,          # hierar chical softmax / default 0\n",
    "    negative = 10   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a4ad569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# Doc2Vec 입력형태를 맞춰줍니다. \n",
    "# TaggedDocument 형태로 ('영화 내용', '제목') 을 받습니다. \n",
    "## 이후, TaggedDocument에 모든 문서에 대해서 '영화 내용', '제목'을 넣어줍니다. \n",
    "agg = df[['title', 'summary']]\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument((c), [d]) for d, c in agg[['title', 'summary']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7875c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n10,hs,w10,mc5,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "# 위에서 만든 tagged_train_docs으로 사전을 만들어줍니다. \n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "602f7d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 303.0115559101105\n"
     ]
    }
   ],
   "source": [
    "# 벡터 문서 학습\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "start = time()\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Doc2Vec 학습을 진행하는데 Learning rate를 계속 감소해주면서 학습을 진행해줍니다. \n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=10)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb307a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('개는 훌륭하다', 0.8033761978149414),\n",
       " ('슬기로운 의사생활', 0.8033228516578674),\n",
       " ('미치지 않고서야', 0.8018646836280823),\n",
       " ('구해줘! 홈즈', 0.7999109625816345),\n",
       " ('골 때리는 그녀들', 0.7987276911735535),\n",
       " ('다모', 0.7923608422279358),\n",
       " ('그것이 알고 싶다', 0.7915096282958984),\n",
       " ('경찰수업', 0.7851594090461731),\n",
       " ('역사저널 그날 시즌2', 0.7817655205726624),\n",
       " ('가요무대', 0.7779215574264526)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy Story와 가장 유사한 상위 20개의 영화를 추출합니다. \n",
    "doc_vectorizer.docvecs.most_similar('사랑의 불시착', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d65240d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3752/1163015398.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc_vectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "doc_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b59f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
